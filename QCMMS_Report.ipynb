{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "QCMMS-Report_hideCode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjsVlhllse_",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "catalogueEndpoint = 'http://qcmms-cat.spacebel.be/eo-catalog'\n",
        "lpProductIdentifier='ProductIdentifierToBeReplaced'\n",
        "lpParentIdentifier= 'ParentIdentifierToBeReplaced'\n",
        "#lpProductIdentifier='IMD_2018_010m'\n",
        "#lpParentIdentifier= 'EOP:ESA:LP:UC1'\n",
        "#lpProductIdentifier='TCCM_1518_020mD'\n",
        "#lpParentIdentifier= 'EOP:ESA:LP:UC2D'\n",
        "debug = False\n",
        "#@title Basic functions\n",
        "import json, requests\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "lpUrl=catalogueEndpoint + '/'+ 'series'+'/' + lpParentIdentifier + '/datasets/'+lpProductIdentifier\n",
        "ipUrl=''\n",
        "lpMd={}\n",
        "platforms=[]\n",
        "fgNbr = 0\n",
        "\n",
        "processingLevelDefs=[\"1C\",\"L1TP\",\"L2A\", \"L2\"]\n",
        "maxRecords = 10\n",
        "\n",
        "pd.set_option('display.html.table_schema', True)\n",
        "\n",
        "def getMetric(metric,feature):\n",
        "    result={}\n",
        "    metrics=feature['properties']['productInformation']['qualityInformation']['qualityIndicators']\n",
        "    lenMetrics= len(metrics)\n",
        "    for i in range(lenMetrics):\n",
        "      if (metrics[i]['isMeasurementOf'] == metric): \n",
        "        result=metrics[i]\n",
        "    if (result == {} and debug):\n",
        "      print(\"metric \", metric,\"not found in \", feature['properties']['identifier'] )\n",
        "    return result\n",
        "\n",
        "def getProcessingLevelIndex(processingLevel):\n",
        "  index=-1\n",
        "  for i in range(len(processingLevelDefs)):\n",
        "    if (processingLevelDefs[i] == processingLevel ): \n",
        "      index=i\n",
        "  return index\n",
        "\n",
        "def generateFigureLabel(fgNbr,label):\n",
        "  lfgNbr=fgNbr+1\n",
        "  display(widgets.HTML(\n",
        "    value='<i>Figure '+ str(lfgNbr) +': ' + label+'</i>'\n",
        "    ))\n",
        "  return lfgNbr\n",
        "\n",
        "def getFigureLabel(fgNbr,label):\n",
        "  return 'Figure '+ str(fgNbr) +': ' + label\n",
        "\n",
        "tableNbr=0\n",
        "def generateTableLabel(tableNbr,label):\n",
        "  lNbr=tableNbr+1\n",
        "  display(widgets.HTML(\n",
        "    value='<i>Table '+ str(lNbr) +': ' + label+'</i>'\n",
        "    ))\n",
        "  return lNbr\n",
        "\n",
        "def displayImage(url):\n",
        "  display(widgets.HTML(\n",
        "  value= '<img width=\"500\" height=\"500\" src=\"'+url+'\">' \n",
        "    ))\n",
        "#@title Retrieving Land Product\n",
        "def getLandProduct():\n",
        "  querystring={}\n",
        "  nbLp=0\n",
        "  lpMd={}\n",
        "  #print(lpUrl)\n",
        "  response = requests.get(lpUrl, params=querystring)\n",
        "  pyresult = json.loads(response.text)\n",
        "  try:\n",
        "    nbLp  = len(pyresult['features'])\n",
        "  except KeyError:\n",
        "    pass\n",
        "  if (nbLp == 0):\n",
        "    print(\"Land Product \" + lpProductIdentifier + \"(\"+ lpParentIdentifier +\") is not found\" )\n",
        "  else:\n",
        "    lpMd = pyresult['features'][0]\n",
        "  return lpMd\n",
        "\n",
        "def getLpAttribute(lpMdProperties,attribute1,attribute2):\n",
        "  res=''\n",
        "  try:\n",
        "    if (attribute2 != ''):\n",
        "      res=lpMdProperties[attribute1][attribute2]\n",
        "    else:\n",
        "      res=lpMdProperties[attribute1]\n",
        "  except KeyError:\n",
        "        pass\n",
        "  return res \n",
        "lpMd=getLandProduct()\n",
        "#@title Retrieving Related Image Products\n",
        "def initImageProductsUrl():\n",
        "  url=''\n",
        "  lp=getLandProduct()\n",
        "  if lp != {}:\n",
        "    try:\n",
        "      url=lp['properties']['links']['via'][0]['href']\n",
        "    except KeyError:\n",
        "      print('Missing via links to Image Products the Land Product') \n",
        "  return url\n",
        "ipUrl=initImageProductsUrl()\n",
        "#@title Retrieving Related Platforms\n",
        "def initPlatforms(lpMd):\n",
        "  nb_platforms=len(lpMd['properties']['acquisitionInformation'])\n",
        "  lplatforms= [''] * nb_platforms    \n",
        "  for i in range(len(lpMd['properties']['acquisitionInformation'])):\n",
        "      lplatforms[i]=lpMd['properties']['acquisitionInformation'][i]['platform']['platformShortName']\n",
        "  return lplatforms\n",
        "platforms=initPlatforms(lpMd)\n",
        "\n",
        "def harmonized():\n",
        "# nbr of platforms is used to decide if we are in multisensor UC.\n",
        "# if yes there some additional information for the harmonization.\n",
        "  if (len(platforms) > 1):\n",
        "    return True;\n",
        "  else:\n",
        "    return False;\n",
        "\n",
        "\n",
        "def countImageProductByMetric(metric,metricValue):\n",
        "   # metric can take values\n",
        "   # degradedDataPercentageMetric\t\t\n",
        "   # degradedAncillaryDataPercentageMetric\t\t\n",
        "   # formatCorrectnessMetric\n",
        "   # generalQualityMetric\t\t\n",
        "   # geometricQualityMetric\t\t\n",
        "   # radiometricQualityMetric\t\t\n",
        "   # sensorQualityMetric\t\n",
        "   # feasibilityControlMetric\t\t\n",
        "   # deliveryControlMetric\t\t\n",
        "   # ordinaryControlMetric\t\t\n",
        "   # detailedControlMetric\n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = 1\n",
        "  if metric != '':\n",
        "    querystring['specificationTitle'] = metric\n",
        "    querystring['degree'] = metricValue\n",
        "  response = requests.get(ipUrl, params=querystring)\n",
        "  pyresult= json.loads(response.text)\n",
        "  return pyresult['totalResults']\n",
        "#\n",
        "# build status for each steps\n",
        "#\n",
        "#\n",
        "# return True if the metric is associated to LP \n",
        "# check if metric contains lp\n",
        "def lpMetric(metric):\n",
        "  if metric.lower().rfind('lp') == -1:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "def  getLpMetricStatus(metricName):\n",
        "  metricPrefix='http://qcmms.esa.int/quality-indicators/#'\n",
        "  metric=getMetric(metricPrefix+metricName,lpMd)\n",
        "  if metric != '{}':\n",
        "    executed=True\n",
        "  else:\n",
        "    executed=False\n",
        "  applicable=True\n",
        "  if metricName == 'lpInterpretationMetric' and harmonized(): \n",
        "    applicable=False\n",
        "  \n",
        "  nbPass=0\n",
        "  nbFailed=0\n",
        "  try:\n",
        "    if metric['value']:\n",
        "      nbPass=1\n",
        "    else:\n",
        "      nbFailed=1\n",
        "  except KeyError:\n",
        "    print(\"key error value\",metric)\n",
        "    pass\n",
        "  result={'Applicable': applicable, 'Executed' : executed, 'PASS': nbPass, 'FAILED' : nbFailed }\n",
        "  return result\n",
        "\n",
        "def getMetricStatus(metric):\n",
        "  if not lpMetric(metric):\n",
        "    nbPass=countImageProductByMetric(metric,'true')\n",
        "    nbFailed=countImageProductByMetric(metric,'false')\n",
        "    applicable=True\n",
        "    if not harmonized() and metric == 'harmonizationControlMetric':\n",
        "      applicable=False\n",
        "    \n",
        "    if nbPass == 0 and nbFailed == 0:\n",
        "      executed=False\n",
        "    else:\n",
        "      executed=True\n",
        "    return {'Applicable': applicable, 'Executed' : executed, 'PASS': nbPass, 'FAILED' : nbFailed }\n",
        "  else:\n",
        "    return getLpMetricStatus(metric)\n",
        "\n",
        "\n",
        "MetricsStatusVct=[\n",
        "                  {'Applicable': True, 'Executed' : True, 'PASS': 1, 'FAILED' :0 },\n",
        "                  getMetricStatus('feasibilityControlMetric'),\n",
        "                  getMetricStatus('deliveryControlMetric'),\n",
        "                  getMetricStatus('ordinaryControlMetric'),\n",
        "                  getMetricStatus('detailedControlMetric'),\n",
        "                  getMetricStatus('harmonizationControlMetric'),\n",
        "                  getMetricStatus('ipForLpInformationMetric'),\n",
        "                  getMetricStatus('lpInterpretationMetric'),\n",
        "                  getMetricStatus('lpMetadataControlMetric'),\n",
        "                  getMetricStatus('lpOrdinaryControlMetric'),\n",
        "                  getMetricStatus('lpThematicValidationMetric')\n",
        "                 ]\n",
        "IndexFeasibility=1\n",
        "IndexDelivery=2\n",
        "IndexOrdinary=3\n",
        "IndexDetailed=4\n",
        "IndexHarmonization=5\n",
        "IndexIpForLp=6\n",
        "IndexLpInterpretation=7\n",
        "IndexLpMetadata=8\n",
        "IndexLpOrdinary=9\n",
        "IndexLpThematic=10\n",
        "#MetricsStatusVct[IndexFeasibility]['Executed']=False\n",
        "#MetricsStatusVct[IndexDelivery]['Applicable']=False\n",
        "\n",
        "\n",
        "def alreadyExecuted(index):\n",
        "  if not MetricsStatusVct[index]['Applicable']:\n",
        "    print(\"This step is not applicable.\")\n",
        "    return False\n",
        "  if not MetricsStatusVct[index]['Executed']:\n",
        "    print(\"This step has not yet been executed.\")\n",
        "    return False\n",
        "  return True\n",
        "#\n",
        "# compute the nbr of PASS/FAILED  for overall assessment and to decide if a step has already been executed.\n",
        "#\n",
        "\n",
        "IPsMetricsStatusVct=[\n",
        "                     {'Metric' :'1. FeasibilityControl',  'Value' : 'PASS' ,  'Nbr' : MetricsStatusVct[IndexFeasibility]['PASS']},\t\n",
        "                     {'Metric' :'1. FeasibilityControl',  'Value' : 'FAILED' ,'Nbr' : MetricsStatusVct[IndexFeasibility]['FAILED'] },\n",
        "                     {'Metric' :'2. DeliveryControl',     'Value' : 'PASS' ,  'Nbr' : MetricsStatusVct[IndexDelivery]['PASS'] },\t\n",
        "                     {'Metric' :'2. DeliveryControl',     'Value' : 'FAILED' ,'Nbr' : MetricsStatusVct[IndexDelivery]['FAILED'] },\n",
        "                     {'Metric' :'3a. OrdinaryControl',    'Value' : 'PASS' ,  'Nbr' : MetricsStatusVct[IndexOrdinary]['PASS'] },\n",
        "                     {'Metric' :'3a. OrdinaryControl',    'Value' : 'FAILED' ,'Nbr' : MetricsStatusVct[IndexOrdinary]['FAILED'] },\t\n",
        "                     {'Metric' :'3b. DetailedControl',    'Value' : 'PASS' ,  'Nbr' : MetricsStatusVct[IndexDetailed]['PASS'] },\t\n",
        "                     {'Metric' :'3b. DetailedControl',    'Value' : 'FAILED' ,'Nbr' : MetricsStatusVct[IndexDetailed]['FAILED'] }\t]\n",
        "if MetricsStatusVct[IndexHarmonization]['Applicable']:\n",
        "  IPsMetricsStatusVct.append({'Metric' :'4a. HarmonizationControl',    'Value' : 'PASS' ,  'Nbr' : MetricsStatusVct[IndexHarmonization]['PASS'] })\n",
        "  IPsMetricsStatusVct.append({'Metric' :'4a. HarmonizationControl',    'Value' : 'FAILED' ,  'Nbr' : MetricsStatusVct[IndexHarmonization]['FAILED']  })\n",
        "\n",
        "def generateDefinitions():\n",
        "  def0= '<tr><td>'+'Circular Error at the 90th percentile' + '</td><td>'+ 'A minimum of 90 percent of the point are included in the stated CE90 circle' + '</td></tr>'\n",
        "  def1= '<tr><td>'+'Image Product' + '</td><td>'+ 'Satellite image data with metadata used as input to Land Mapping Production.' + '</td></tr>'\n",
        "  def2= '<tr><td>'+'Land Product'+ '</td><td>' + 'Land Mapping or Monitoring Product as e.g. Land Cover Map.'+'</td></tr>' \n",
        "  def3= '<tr><td>'+'Land Product Specification Table'+'</td><td>'+ 'Set of parameters that defines the Land Product and the required Image Products.'+'</td></tr>' \n",
        "  def4= '<tr><td>'+'Root Mean Square Error' +'</td><td>'+  'The standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.' +'</td></tr>' \n",
        "  definitions= '<table border=1 width=80%>' + def0 + def1 + def2 + def3 + '</table>'\n",
        "  display(widgets.HTML(\n",
        "    value=definitions\n",
        "    ))\n",
        "\n",
        "def generateAbbreviations():\n",
        "  def0= '<tr><td>'+'CE90' + '</td><td>'+ 'Circular Error at the 90th percentile' + '</td></tr>'\n",
        "  def1= '<tr><td>'+'EO' + '</td><td>'+ 'Earth Observation' + '</td></tr>'\n",
        "  def2= '<tr><td>'+'HR' + '</td><td>'+ 'High Resolution' + '</td></tr>'\n",
        "  def3= '<tr><td>'+'HRL' + '</td><td>'+ 'High Resolution Layer' + '</td></tr>'\n",
        "  def4= '<tr><td>'+'IP' + '</td><td>'+ 'Image Product' + '</td></tr>'\n",
        "  def5= '<tr><td>'+'INSPIRE' + '</td><td>'+ 'Infrastructure for Spatial Information in Europe' + '</td></tr>'\n",
        "  def6= '<tr><td>'+'LCCM' + '</td><td>'+ 'Land Cover Continuous Monitoring' + '</td></tr>'\n",
        "  def7= '<tr><td>'+'LP'+  '</td><td>' + 'Land Product' + '</td></tr>'\n",
        "  def8= '<tr><td>'+'MMU'+  '</td><td>' + 'Minimum Mapping Unit' + '</td></tr>'\n",
        "  def9= '<tr><td>'+'RMSE'+  '</td><td>' + 'Root Mean Square Error' + '</td></tr>'\n",
        "  def10= '<tr><td>'+'VHR'+  '</td><td>' + 'Very High Resolution' + '</td></tr>'\n",
        "  definitions= '<table border=1 width=80%>' + def0+ def1 + def2 + def3 + def4 + def5 + def6 + def7+ def8+ def9+ def10+'</table>'\n",
        "  display(widgets.HTML(\n",
        "    value=definitions\n",
        "    ))\n",
        "\n",
        "#@title Generate Land Product Definition\n",
        "def generate_lp_definition_report():\n",
        "  table_title =['Parameter','Value/Description']\n",
        "  \n",
        "  table_report = []\n",
        "  lpMd = getLandProduct()\n",
        "  if(lpMd != {}):\n",
        "    abstract=lpMd['properties']['abstract']\n",
        "    display(widgets.HTML(\n",
        "       value= abstract ))\n",
        "       \n",
        "    table_report=[\n",
        "      ['Product',getLpAttribute(lpMd['properties'],'title','')],\n",
        "      ['Product type',getLpAttribute(lpMd['properties'],'additionalAttributes','product_type')],   \n",
        "      ['Geometric resolution',getLpAttribute(lpMd['properties'],'additionalAttributes','geometric_resolution')],\n",
        "      ['Target CRS',getLpAttribute(lpMd['properties'],'additionalAttributes','crs')], \n",
        "      ['Geometric accuracy',getLpAttribute(lpMd['properties'],'additionalAttributes','geometric_accuracy')], \n",
        "      ['Thematic accuracy',getLpAttribute(lpMd['properties'],'additionalAttributes','thematic_accuracy')], \n",
        "      ['MMU',getLpAttribute(lpMd['properties'],'additionalAttributes','mmu_pixels')],  \n",
        "      ['Attributes',getLpAttribute(lpMd['properties'],'additionalAttributes','attributes')],\n",
        "      ['Raster coding',getLpAttribute(lpMd['properties'],'additionalAttributes','raster_coding')],\n",
        "      ['Coverage area',getLpAttribute(lpMd['properties'],'additionalAttributes','coverage_area')],\n",
        "      ['Reference year',getLpAttribute(lpMd['properties'],'additionalAttributes','reference_year')],\n",
        "      ['Temporal window',getLpAttribute(lpMd['properties'],'additionalAttributes','temporal_window')],\n",
        "      ['Primary image resource',getLpAttribute(lpMd['properties'],'additionalAttributes','primary_image_source')]              \n",
        "    ]\n",
        "    table_index = ['','','','','','','','','','','','','']\n",
        "    pd_report = pd.DataFrame(table_report , index=table_index,columns = table_title)\n",
        "    #pd_report.head()\n",
        "    display(pd_report)\n",
        "   \n",
        "\n",
        "#@title Generate Feasibility Control Report\n",
        "def generate_feasibility_control_report(platform):\n",
        "  querystring = {}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  table_title =['Format correctness','General quality', 'Geometric quality', 'Radiometric quality', 'Sensor quality', 'Total']\n",
        "  metrics=['formatCorrectnessMetric','generalQualityMetric','geometricQualityMetric','radiometricQualityMetric','sensorQualityMetric','feasibilityControlMetric']\n",
        "  degrees=['true','false']\n",
        "  table_report=[ [0]*len(table_title) for i in range(len(degrees))]\n",
        "  for i in range(len(degrees)):\n",
        "    querystring['degree'] = degrees[i]\n",
        "    for j in range (len(metrics)):\n",
        "      querystring['specificationTitle'] = metrics[j]\n",
        "      response = requests.get(ipUrl, params=querystring)\n",
        "      table_report[i][j]=json.loads(response.text)['totalResults'] \n",
        "  pd_report = pd.DataFrame(table_report , index = ['TRUE', 'FALSE'], columns = table_title)\n",
        "  display(pd_report)\n",
        "  display(widgets.HTML(value='<br>'))\n",
        "\n",
        "\n",
        "#@title Generate Frequency Plot of Cloud Cover\n",
        "\n",
        "def generateHist(fgNbr,platform):\n",
        "  querystring = {}\n",
        "  cloudCvPctVt=[]\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex\n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    for i in range(lenFeatures):\n",
        "      try:\n",
        "        cloudCvPctVt.append(pyresult['features'][i] ['properties']['productInformation']['cloudCover'])\n",
        "       # print (pyresult['features'][i] ['properties']['productInformation']['cloudCover'])\n",
        "      except KeyError:\n",
        "        pass\n",
        "  fgNbr=fgNbr+1\n",
        "  df = pd.DataFrame({getFigureLabel(fgNbr,\"Frequency plot of the cloud cover % for \" + platform )+' \\n \\n cloudPct': cloudCvPctVt}) \n",
        "  hist = df.hist(bins=100)\n",
        "  display(widgets.HTML(value='<br>'))\n",
        "  \n",
        "  return fgNbr\n",
        "\n",
        "#generateHist(fgNbr,'Sentinel-2')\n",
        "#@title Generate Delivery Control Report\n",
        "def generate_delivery_control_report(platform):\n",
        "  \n",
        "  def fillReportTable(processingLevel, deliveryControlMetric,table):\n",
        "    col=getProcessingLevelIndex(processingLevel)\n",
        "    if (col != -1):\n",
        "      if deliveryControlMetric['complete']:\n",
        "        table[0][col]=table[0][col]+1\n",
        "      else:\n",
        "        table[1][col]=table[1][col]+1\n",
        "      if (deliveryControlMetric['status'] == \"WAITING\"):\n",
        "        table[2][col]=table[2][col]+1\n",
        "      elif (deliveryControlMetric['status'] == \"IN_PROGRESS\"):\n",
        "        table[3][col]=table[3][col]+1\n",
        "    else:\n",
        "      print('processingLevel ' + processingLevel)\n",
        "  \n",
        "  def completeReportTable(table):\n",
        "    for i in range(len(table)):\n",
        "      nbcol=len(table[i])-1     \n",
        "      for j in range(nbcol):    \n",
        "        table[i][nbcol]=table[i][nbcol]+table[i][j]\n",
        "  table_title = ['L1','L1TP','L2A', 'L2 Processor', 'Total']\n",
        "  table_index = ['TRUE','FALSE', 'WAITING', 'IN_PROGRESS']\n",
        "  metric=\"http://qcmms.esa.int/quality-indicators/#deliveryControlMetric\"\n",
        "\n",
        "  table_report=[ [0]*5 for i in range(4)]\n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex\n",
        "    querystring['platform'] = platform\n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    for i in range(lenFeatures):\n",
        "      #print(pyresult['features'][i] ['properties']['identifier'] )\n",
        "      processingLevel=pyresult['features'][i]['properties']['productInformation']['processingLevel']        \n",
        "      deliveryControlMetric=getMetric(metric,pyresult['features'][i])\n",
        "      if (deliveryControlMetric != {}):\n",
        "        fillReportTable(processingLevel, deliveryControlMetric, table_report)\n",
        "  completeReportTable(table_report)\n",
        "  pd_report = pd.DataFrame(table_report ,index = table_index, columns = table_title)\n",
        "  display(pd_report)   \n",
        "  display(widgets.HTML(value='<br>')) \n",
        "#generate_delivery_control_report('LANDSAT-8')\n",
        "#generate_delivery_control_report('Sentinel-2')\n",
        "#@title Generate Ordinary Control Report\n",
        "def generate_ordinary_control_report(platform):\n",
        "  \n",
        "\n",
        "\n",
        " \n",
        "  \n",
        "  def initTableReport():\n",
        "    table=[ [\"FALSE\",0,0,0,0,0] for i in range(len(procLevelDefs)*2)]\n",
        "    for i in range(len(procLevelDefs)):\n",
        "      table[i*2][0]=\"TRUE\"\n",
        "    return table\n",
        "  \n",
        "  def getAttribute(attribute, metric):\n",
        "    result={'present' : True,'value':True}\n",
        "    try:\n",
        "      result['value']=metric[attribute]\n",
        "    except KeyError:\n",
        "      result['present'] = False\n",
        "    return result\n",
        "  \n",
        "  def getMetricValue(metricValue):\n",
        "    result={'present' : True,'value':True}\n",
        "    try:\n",
        "      result['value']=metricValue\n",
        "    except KeyError:\n",
        "      result['present'] = False\n",
        "    return result\n",
        "\n",
        "  def getRaster(ordinaryControlMetric):\n",
        "    result={}\n",
        "    try:\n",
        "      result=ordinaryControlMetric['harmonized']['tile'][0]['raster']\n",
        "    except KeyError:\n",
        "      pass\n",
        "    return result\n",
        "\n",
        "\n",
        "  def fillReportByLevel(level,ordinaryControlMetric):\n",
        "    try:\n",
        "      # compute table from rastsers complete to end\n",
        "      table_row=[{'present' : False,'value':True},\n",
        "                 {'present' : False,'value':True},\n",
        "                 {'present' : False,'value':True},\n",
        "                 {'present' : False,'value':True},\n",
        "                 {'present' : False,'value':True},\n",
        "                 {'present' : False,'value':True}]\n",
        "      # prepare working row to avoid list of if else for all columns\n",
        "      if (level=='harmonized'):\n",
        "        raster=getRaster(ordinaryControlMetric)\n",
        "        if (raster != {}):\n",
        "          table_row[0] = getAttribute('rastersComplete', raster) \n",
        "          table_row[1] = getAttribute('rastersRead', raster)     \n",
        "          table_row[2] = getAttribute('calibrationMetadata', raster)     \n",
        "          table_row[3] = getAttribute('metadataRead', raster)  \n",
        "          table_row[4] = getMetricValue(ordinaryControlMetric['value']) \n",
        "      else:\n",
        "        table_row[0] = getAttribute('rastersComplete', ordinaryControlMetric[level]) \n",
        "        table_row[1] = getAttribute('rastersRead', ordinaryControlMetric[level])     \n",
        "        table_row[2] = getAttribute('calibrationMetadata', ordinaryControlMetric[level])     \n",
        "        table_row[3] = getAttribute('metadataRead', ordinaryControlMetric[level])  \n",
        "        table_row[4] = getMetricValue(ordinaryControlMetric['value']) \n",
        "  #    table_row[5] = getAttribute('rows', ordinaryControlMetric[level])\n",
        "     \n",
        "      #table_index=processingLevelIndex*2\n",
        "      if (level=='level1'):\n",
        "        table_index=0\n",
        "      elif (level=='level2'):\n",
        "        table_index=2\n",
        "      else:\n",
        "        table_index=4\n",
        "      # for each columns, the row is determined by the processing level &\n",
        "      # and boolean value of the corresponding attribute\n",
        "      # the second column has already been filled by the table initialisation\n",
        "      # note that the titles and first column are not part of the table\n",
        "      # are passed at the dataframe construction\n",
        "\n",
        "      # for each column\n",
        "      for i in range(len(table_row)):\n",
        "        if (table_row[i]['present']):\n",
        "          # compute table index = table row nbr\n",
        "          # second line of boolean is false \n",
        "          if (table_row[i]['value']):\n",
        "            ti = table_index\n",
        "          else:\n",
        "            ti = table_index+1\n",
        "          # compute table column, first columns is fixed.\n",
        "          tc=i+1 \n",
        "          table_report[ti][tc]=table_report[ti][tc]+1\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  def fillReportTable(processingLevel, ordinaryControlMetric):\n",
        "    processingLevelIndex=getProcessingLevelIndex(processingLevel)\n",
        "    #print(\"level \",processingLevel, \"index \",processingLevelIndex)\n",
        "    if (processingLevelIndex != -1):\n",
        "      fillReportByLevel('level1',ordinaryControlMetric)\n",
        "      fillReportByLevel('level2',ordinaryControlMetric)\n",
        "      if harmonized():\n",
        "         fillReportByLevel('harmonized',ordinaryControlMetric)\n",
        "  \n",
        "  procLevelDefs=['L1', 'L2']\n",
        "  table_index = [procLevelDefs[0],'', procLevelDefs[1],'']\n",
        "  if harmonized():    \n",
        "    procLevelDefs=['L1', 'L2','LH'] \n",
        "    table_index = [procLevelDefs[0],'', procLevelDefs[1],'', procLevelDefs[2],'']\n",
        "  \n",
        "  table_title = ['Eval.','Rasters complete', 'Rasters read', 'Calibration metadata', 'Metadata read','Total' ]\n",
        "  \n",
        "\n",
        "  \n",
        "  metric=\"http://qcmms.esa.int/quality-indicators/#ordinaryControlMetric\"\n",
        "\n",
        "  table_report=initTableReport()  \n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex\n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    for i in range(lenFeatures):\n",
        "      processingLevel=pyresult['features'][i]['properties']['productInformation']['processingLevel']\n",
        "      ordinaryControlMetric=getMetric(metric,pyresult['features'][i])\n",
        "      if (ordinaryControlMetric != {}):\n",
        "        fillReportTable(processingLevel, ordinaryControlMetric)\n",
        "  #print(\"end report\")\n",
        "  \n",
        "  pd_report = pd.DataFrame(table_report ,index = table_index, columns = table_title)\n",
        "  display(pd_report)\n",
        "  display(widgets.HTML(value='<br>'))\n",
        "#generate_ordinary_control_report(\"LANDSAT-8\")\n",
        "#generate_ordinary_control_report(\"Sentinel-2\")\n",
        "#@title Generate Detailed Control Report\n",
        "def generate_detailed_control_report(platform):\n",
        "  \n",
        "  def fillReportTableCell(tc,detailedControlMetric, attributeName, metricId):\n",
        "    ti=1\n",
        "    try:\n",
        "      vect=detailedControlMetric[attributeName]\n",
        "      for i in range(len(vect)):\n",
        "        if ( (vect[i][\"id\"]==metricId) and (vect[i][\"mask\"]!=\"\" )):\n",
        "          ti=0\n",
        "    except KeyError:\n",
        "      pass\n",
        "    table_report[ti][tc]=table_report[ti][tc]+1\n",
        "    #print(ti, tc, table_report[ti][tc] )\n",
        "\n",
        "  def fillReportTableLastCell(tc,detailedControlMetric):\n",
        "    ti=1\n",
        "    try:\n",
        "      if (detailedControlMetric['value']):\n",
        "        ti=0\n",
        "    except KeyError:\n",
        "      pass\n",
        "    table_report[ti][tc]=table_report[ti][tc]+1\n",
        "    #print(ti, tc, table_report[ti][tc] )\n",
        "\n",
        "  def fillReportTable(detailedControlMetric):\n",
        "    fillReportTableCell(0,detailedControlMetric, \"cloudCover\", \"http://qcmms.esa.int/detailed_control#CLOUD_COVER\")\n",
        "    fillReportTableCell(1,detailedControlMetric, \"cloudCover\", \"http://qcmms.esa.int/detailed_control#ALTERNATE_CLOUD_COVER\")\n",
        "    fillReportTableCell(2,detailedControlMetric, \"geometry\", \"http://qcmms.esa.int/detailed_control#GEOMETRY\")\n",
        "    fillReportTableCell(3,detailedControlMetric, \"validPixels\", \"http://qcmms.esa.int/detailed_control#VALID_PIXELS\")\n",
        "    fillReportTableLastCell(4,detailedControlMetric)\n",
        "\n",
        "  table_title = ['MeanCloud cover layer','Cloud cover alternative layer', 'Geometry val.layer', 'Valid pixel metadata', 'TOTAL' ]\n",
        "  table_index = ['TRUE','FALSE']\n",
        "  metric=\"http://qcmms.esa.int/quality-indicators/#detailedControlMetric\"\n",
        "  table_report=[ [0,0,0,0,0],  [0,0,0,0,0]]  \n",
        "\n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex   \n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    for i in range(lenFeatures):\n",
        "      detailedControlMetric=getMetric(metric,pyresult['features'][i])\n",
        "      if (detailedControlMetric != {}):\n",
        "        fillReportTable(detailedControlMetric)\n",
        "  pd_report = pd.DataFrame(table_report ,index = table_index, columns = table_title)\n",
        "  display(pd_report)   \n",
        "  \n",
        "  display(widgets.HTML(value='<br>'))\n",
        "#generate_detailed_control_report()\n",
        "#@title Generate Detailed Control Stat Report\n",
        "def generate_detailed_control_stat_report(platform):\n",
        "  \n",
        "  def fillReportTableCell(tc,detailedControlMetric, attributeName1,attributeName2,metricId):\n",
        "    \n",
        "    try:\n",
        "      vect=detailedControlMetric[attributeName1]\n",
        "      for i in range(len(vect)):\n",
        "        if (vect[i][\"id\"]==metricId):\n",
        "          table_report[tc]=table_report[tc]+vect[i][attributeName2]\n",
        "          table_number[tc]=table_number[tc]+1\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  def fillReportTableCellDiff(tc,detailedControlMetric,attributeName1, attributeName2,  metricId,diffMaxLimit):\n",
        "    try:\n",
        "      vect=detailedControlMetric[attributeName1]\n",
        "      for i in range(len(vect)):\n",
        "        if (vect[i][\"id\"]==metricId):\n",
        "          if vect[i][attributeName2] > diffMaxLimit:\n",
        "            table_report[tc]=table_report[tc]+1          \n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  def computeMean():\n",
        "    for i in range(len(table_number)):\n",
        "      if (table_number[i] != 0):\n",
        "        table_report[i] = table_report[i] / table_number[i]\n",
        "\n",
        "  def fillReportTable(detailedControlMetric):\n",
        "    fillReportTableCell(0,detailedControlMetric, \"cloudCover\",  \"cloudPct\", \"http://qcmms.esa.int/detailed_control#CLOUD_COVER\")\n",
        "    fillReportTableCell(1,detailedControlMetric, \"cloudCover\",  \"cloudPct\", \"http://qcmms.esa.int/detailed_control#ALTERNATE_CLOUD_COVER\")\n",
        "    fillReportTableCell(2,detailedControlMetric, \"geometry\",    \"rmseX\",    \"http://qcmms.esa.int/detailed_control#GEOMETRY\")\n",
        "    fillReportTableCell(3,detailedControlMetric, \"geometry\",    \"rmseY\",    \"http://qcmms.esa.int/detailed_control#GEOMETRY\")\n",
        "    fillReportTableCell(6,detailedControlMetric, \"validPixels\", \"validPct\",  \"http://qcmms.esa.int/detailed_control#VALID_PIXELS\")\n",
        "    fillReportTableCellDiff(4,detailedControlMetric, \"geometry\", \"diffXmax\",  \"http://qcmms.esa.int/detailed_control#GEOMETRY\",diffMaxLimit)\n",
        "    fillReportTableCellDiff(5,detailedControlMetric, \"geometry\", \"diffYmax\",  \"http://qcmms.esa.int/detailed_control#GEOMETRY\",diffMaxLimit)\n",
        "    \n",
        "  table_index = ['']\n",
        "  table_title = ['Mean\\\\nCloud cover','Mean\\\\nCloud alternative', 'Mean\\\\nGeometry RmseX', 'Mean\\\\nGeometry RmseY','Nb > 5\\\\nGeometry DiffxMaX', 'Nb > 5\\\\nDiffy Max' ,'Mean\\\\nValid Pixels' ]\n",
        "  table_number =[   0,               0,                 0,                 0,                1,                1,           0]  # used to compute mean when required.\n",
        "  metric=\"http://qcmms.esa.int/quality-indicators/#detailedControlMetric\"\n",
        "  diffMaxLimit = 5\n",
        "  table_report=[0,0,0,0,0,0,0]  \n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex\n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    for i in range(lenFeatures):\n",
        "      detailedControlMetric=getMetric(metric,pyresult['features'][i])\n",
        "      if (detailedControlMetric != {}):\n",
        "        fillReportTable(detailedControlMetric)\n",
        "  computeMean()\n",
        "  table_report2=[table_report]\n",
        "  pd_report = pd.DataFrame(table_report2,index = table_index, columns = table_title)\n",
        "  #display(pd_report)  \n",
        "  pretty_print(pd_report)\n",
        "  display(widgets.HTML(value='<br>')) \n",
        "# generate_detailed_control_stat_report()\n",
        "#@title Plot CE\n",
        "def generate_Plot_CE(fgNbr,platform):\n",
        "\n",
        "  def computeCircularError(percentile):\n",
        "    # compute the index in the sorted array to have the required percentage (percentile)  of points inside the circle of center 0,0 and radius = that distance \n",
        "    index=math.ceil((pd_report.size/3)*(percentile/100.0))\n",
        "    # return the computed distance (column=2) \n",
        "    return pd_report.iat[index-1,2]\n",
        "\n",
        "  def plotCE(ce,title):\n",
        "    x_vec=pd_report['diffXmax'].values.tolist()\n",
        "    y_vec=pd_report['diffYmax'].values.tolist()\n",
        "    plt.scatter(x_vec,y_vec)\n",
        "    fig=plt.gcf()\n",
        "    ax=fig.gca()\n",
        "    ax.axis('equal')\n",
        "    #plt.ioff()\n",
        "    #plt.hold(False)\n",
        "    #print(\"interactive \",plt.isinteractive())\n",
        "    title=title+' \\n\\n ' + 'CE'+str(percentile) + \" = \" + str(round(ce,1))\n",
        "    plt.title(title) \n",
        "  #  plt.title(title + ' \n",
        "  #  CE'+str(percentile) + \" = \" + str(round(ce,1)))\n",
        "    plt.xlabel(\"x-offset\")\n",
        "    plt.ylabel(\"y-offset\")\n",
        "    ce_circle=plt.Circle((0,0),ce,edgecolor='r',fill=False)\n",
        "    ax.add_artist(ce_circle)\n",
        "    plt.show()\n",
        "\n",
        "  def distFromOrigin(xMax,yMax):\n",
        "    return math.sqrt(xMax*xMax+yMax*yMax)\n",
        "  \n",
        "  def fillReportTableCell(detailedControlMetric,attributeName,  metricId):\n",
        "    try:\n",
        "      vect=detailedControlMetric[attributeName]\n",
        "      for i in range(len(vect)):\n",
        "        if (vect[i][\"id\"]==metricId):\n",
        "          xMax=vect[i]['diffXmax']\n",
        "          yMax=vect[i]['diffYmax']\n",
        "          dist=distFromOrigin(xMax,yMax)\n",
        "          table_report.append([xMax,yMax,dist])\n",
        "        \n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  def fillReportTable(detailedControlMetric):\n",
        "    fillReportTableCell(detailedControlMetric, \"geometry\", \"http://qcmms.esa.int/detailed_control#GEOMETRY\")\n",
        "     \n",
        "  metric=\"http://qcmms.esa.int/quality-indicators/#detailedControlMetric\"  \n",
        "  querystring={}\n",
        "  querystring['maximumRecords'] = maxRecords\n",
        "  querystring['platform'] = platform\n",
        "  totalResults=1\n",
        "  startIndex=1\n",
        "  table_report=[]\n",
        "  table_column=['diffXmax','diffYmax','distance']\n",
        "  percentile=90\n",
        "  dataAvailable = False\n",
        "  while (startIndex<=totalResults):\n",
        "    querystring['startRecord'] = startIndex\n",
        "    \n",
        "    response = requests.get(ipUrl, params=querystring)\n",
        "    pyresult= json.loads(response.text)\n",
        "    lenFeatures= len(pyresult['features'])\n",
        "   \n",
        "    \n",
        "    startIndex=startIndex+maxRecords\n",
        "    totalResults=pyresult['totalResults']\n",
        "    if(lenFeatures > 0):\n",
        "       for i in range(lenFeatures):\n",
        "          detailedControlMetric=getMetric(metric,pyresult['features'][i])           \n",
        "          fillReportTable(detailedControlMetric)\n",
        "          dataAvailable = True\n",
        "  if(dataAvailable):\n",
        "     pd_report = pd.DataFrame(table_report,columns=table_column)\n",
        "     pd_report.sort_values([\"distance\"],axis=0,ascending=[True],inplace=True)\n",
        "     #display(pd_report)\n",
        "     fgNbr=fgNbr+1\n",
        "     title=getFigureLabel(fgNbr,\"Geometry validation results, requirement: geometry quality < 0.5 pixel of 10 m for \" + platform )\n",
        "     circularError=computeCircularError(percentile)\n",
        "     plotCE(circularError, title)\n",
        "     #pd_report.plot.scatter(x='diffXmax',y='diffYmax') \n",
        "  return fgNbr  \n",
        "#generate_Plot_CE(0 ,'LANDSAT-8')\n",
        "#@title Fit-for-Purpose\n",
        "def getFitForPurpose(fgNbr):\n",
        "  lpMd=getLandProduct()\n",
        "  if(lpMd != {}):\n",
        "    metric=getMetric(\"http://qcmms.esa.int/quality-indicators/#ipForLpInformationMetric\",lpMd)\n",
        "    for year in sorted(metric['vpxCoverage'].keys()):\n",
        "      image=metric['vpxCoverage'][year]['mask']\n",
        "      displayImage(image)\n",
        "      fgNbr=generateFigureLabel(fgNbr,\"Fit For Purpose mask year \" + year)\n",
        "  return fgNbr\n",
        "    #print (image)\n",
        "    #  for att in dir(metric['vpxCoverage']):\n",
        "    #  print (att, getattr(metric['vpxCoverage'],att))\n",
        "#@title Production Quality Indicators\n",
        "def generate_production_and_validation_quality_indicators_report(metricId):\n",
        " \n",
        "  lpMd=getLandProduct()\n",
        "  if(lpMd != {}):\n",
        "    metric=getMetric(metricId,lpMd)\n",
        "    \n",
        "    if (metric != {}):\n",
        "      try:\n",
        "        # urban_index=metric['classification']['codingClasses']['urban']\n",
        "        # non_urban_index=metric['classification']['codingClasses']['non-urban']\n",
        "        nb_classes=len(metric['classification']['codingClasses'])\n",
        "       \n",
        "        table_index = [''] * nb_classes\n",
        "        table_title=[''] * (nb_classes+1)\n",
        "       \n",
        "        table_title[0]='Class / \\\\nIndicator'\n",
        "   \n",
        "        for i in range(nb_classes):\n",
        "          table_title[i+1]='\\\\n'+metric['classification']['codingClasses'][i]\n",
        "        middle_col=nb_classes//2+1\n",
        "        table_title[middle_col]='REFERENCE'+table_title[middle_col]\n",
        "        table_report=[ [0]*len(table_title) for i in range(nb_classes)]\n",
        "      except KeyError:\n",
        "         print(\"Metric \",metricId,\": missing codingClasses\")\n",
        "      \n",
        "      try:\n",
        "        confusionMatrix=metric['classification']['confusionMatrix']\n",
        "        for i in range(nb_classes):\n",
        "          table_report[i][0]=metric['classification']['codingClasses'][i]\n",
        "          for j in range (nb_classes):\n",
        "            table_report[i][j+1]=confusionMatrix[i][j] \n",
        "        pd_report = pd.DataFrame(table_report ,index = table_index, columns = table_title)       \n",
        "        pretty_print(pd_report)\n",
        "      except KeyError:\n",
        "        print(\"Missing confusionMatrix\")  \n",
        "      \n",
        "      display(widgets.HTML(value='<br><br>'))\n",
        " #    display other parameters\n",
        " #\n",
        "      table_report=[\n",
        "      ['Kappa',             getClassificationAttribute(metric['classification'],'kappa')],\n",
        "      ['Overall Accuracy',  getClassificationAttribute(metric['classification'],'overallAccuracy')],   \n",
        "      ['Producers Accuracy',getClassificationAttribute(metric['classification'],'producersAccuracy')],\n",
        "      ['Users Accuracy',    getClassificationAttribute(metric['classification'],'usersAccuracy')]             \n",
        "      ]\n",
        "      table_index = ['','','','']\n",
        "      table_title =['Other Parameters','Value']\n",
        "      pd_report = pd.DataFrame(table_report , index=table_index,columns = table_title)\n",
        "      display(pd_report)\n",
        "\n",
        "    \n",
        "        \n",
        "\n",
        "def getClassificationAttribute(classification,attribute):\n",
        "  res=''\n",
        "  try:\n",
        "      res=classification[attribute]\n",
        "  except KeyError:\n",
        "        pass\n",
        "  return res \n",
        "\n",
        "\n",
        "def pretty_print(df):\n",
        "    return display(HTML(df.to_html().replace('\\\\n',\"<br>\")))\n",
        "\n",
        "def displayIPsStatusBarchart():\n",
        "  df = pd.DataFrame(IPsMetricsStatusVct)\n",
        "  df.groupby(['Metric','Value']).sum().unstack().plot(kind='bar')\n",
        "    \n",
        "def cvNaFlag(flagApplicable):\n",
        "  if not flagApplicable:\n",
        "    return 'N/A'\n",
        "  else:\n",
        "    return ''\n",
        "\n",
        "def cvExecutedFlag(statusObject):\n",
        "  if not statusObject['Applicable']:\n",
        "    return \"N/A\"\n",
        "  elif statusObject['Executed']:\n",
        "    return 'Executed'\n",
        "  else:\n",
        "    return 'Not Executed'\n",
        "\n",
        "def cvLpStatus(statusObject):\n",
        "  if not statusObject['Applicable']:\n",
        "    return \"N/A\"\n",
        "  elif not statusObject['Executed']:\n",
        "    return 'Not Executed'\n",
        "  elif statusObject['PASS']==1 :\n",
        "    return 'PASS'\n",
        "  else:\n",
        "    return 'Failed'\n",
        "    \n",
        "\n",
        "def getAssessmentStatus():\n",
        "  incomplete=False\n",
        "  for i in range(len(MetricsStatusVct)):\n",
        "    if MetricsStatusVct[i]['Applicable'] and not MetricsStatusVct[i]['Executed']:\n",
        "      incomplete=True  \n",
        "  if incomplete:\n",
        "    return 'Incomplete'  \n",
        "  if MetricsStatusVct[IndexLpMetadata]['PASS']==1 and MetricsStatusVct[IndexLpOrdinary]['PASS']==1 and MetricsStatusVct[IndexLpThematic]['PASS']==1:\n",
        "    return 'PASS'\n",
        "  else:\n",
        "    return 'FAILED'\n",
        "\n",
        "#generate_production_and_validation_quality_indicators_report(\"http://qcmms.esa.int/quality-indicators/#lpInterpretationMetric\")\n",
        "#@title Generate Overall Assessment\n",
        "def generate_overall_assessment():\n",
        "  table_title =['Task','Assessment', 'Status','Nb Pass','Nb Failed']\n",
        "  table_index = ['','','','','','','','','','','','']\n",
        "  table_report = []\n",
        "  lpMd = getLandProduct()\n",
        "  nb_ip=countImageProductByMetric('','')\n",
        "  if(lpMd != {}):\n",
        "    \n",
        "    table_report=[\n",
        "      ['0.','Land Product Definitions','PASS','',''],\n",
        "      ['1.','Production Feasibility',                cvExecutedFlag(MetricsStatusVct[IndexFeasibility]),\n",
        "             MetricsStatusVct[IndexFeasibility]['PASS'],MetricsStatusVct[IndexFeasibility]['FAILED']],   \n",
        "      ['2.','Delivery Control (images availability)',cvExecutedFlag(MetricsStatusVct[IndexDelivery]),\n",
        "             MetricsStatusVct[IndexDelivery]['PASS'],MetricsStatusVct[IndexDelivery]['FAILED']],\n",
        "      ['3A.','Ordinary Control (scene-level)', cvExecutedFlag(MetricsStatusVct[IndexOrdinary]),\n",
        "             MetricsStatusVct[IndexOrdinary]['PASS'],MetricsStatusVct[IndexOrdinary]['FAILED']], \n",
        "      ['3B.','Detailed Control (pixel-level)', cvExecutedFlag(MetricsStatusVct[IndexDetailed]),\n",
        "             MetricsStatusVct[IndexDetailed]['PASS'],MetricsStatusVct[IndexDetailed]['FAILED']], \n",
        "      ['4A.','Harmonization',                  cvExecutedFlag(MetricsStatusVct[IndexHarmonization]),\n",
        "             MetricsStatusVct[IndexHarmonization]['PASS'],MetricsStatusVct[IndexHarmonization]['FAILED']],\n",
        "      ['4B.','Fit-for-purpose',                cvLpStatus(MetricsStatusVct[IndexIpForLp]),         \n",
        "             MetricsStatusVct[IndexIpForLp]['PASS'],MetricsStatusVct[IndexIpForLp]['FAILED']],  \n",
        "      ['5.','Production Quality Indicators',   cvLpStatus(MetricsStatusVct[IndexLpInterpretation]),\n",
        "             MetricsStatusVct[IndexLpInterpretation]['PASS'],MetricsStatusVct[IndexLpInterpretation]['FAILED']],\n",
        "      ['6A.','Metadata Control Indicators',    cvLpStatus(MetricsStatusVct[IndexLpMetadata]),\n",
        "             MetricsStatusVct[IndexLpMetadata]['PASS'],MetricsStatusVct[IndexLpMetadata]['FAILED']],\n",
        "      ['6B.','Ordinary Control Indicators',    cvLpStatus(MetricsStatusVct[IndexLpOrdinary]),      \n",
        "             MetricsStatusVct[IndexLpOrdinary]['PASS'],MetricsStatusVct[IndexLpOrdinary]['FAILED']],\n",
        "      ['6C.','Thematic Validation Indicators', cvLpStatus(MetricsStatusVct[IndexLpThematic]),      \n",
        "             MetricsStatusVct[IndexLpThematic]['PASS'],MetricsStatusVct[IndexLpThematic]['FAILED']],\n",
        "      ['7.','Overall assessment (delivery?)',getAssessmentStatus(), '','']              \n",
        "    ]\n",
        "    \n",
        "    pd_report = pd.DataFrame(table_report , index=table_index,columns = table_title)\n",
        "    display(pd_report)\n",
        "\n",
        "     \n",
        "#@title Interpretation Form (not used)\n",
        "#\n",
        "# Store and retrieve in a file (JSON object stored as a string in a file)\n",
        "# the text entered by the user in the all textarea associated to the different tables/figures of the report\n",
        "interpretationFile = 'interpretations.json'\n",
        "interpretationList=['feasibility','cloudPercentages','delivery','ordinary','detailed','detailedStat','geometry']\n",
        "#  object that with attributes above and text read and entered by the user\n",
        "interpretationTexts={}\n",
        "# object that contains for each textarea the associated widget object\n",
        "interpretationWdgts={}\n",
        "defaultText=''\n",
        "wdgtPlaceHolder='Enter your interpretation for '\n",
        "\n",
        "def initInterpretationTexts():\n",
        "# read interpretation comment from a file located in the same place than the notebook\n",
        "  interpretations={}\n",
        "  try:\n",
        "    with open(interpretationFile) as json_file:\n",
        "      interpretations = json.load(json_file)\n",
        "#     check that different text areas had been save. Initialize new textareas (update report definition).\n",
        "      for i in range(len(interpretationList)):\n",
        "        try:\n",
        "          interpretationName=interpretations[interpretationList[i]]\n",
        "        except KeyError:\n",
        "          interpretations[interpretationName]=defaultText \n",
        "  except Exception as e:\n",
        "    for i in range(len(interpretationList)):\n",
        "      interpretationName=interpretationList[i]\n",
        "      interpretations[interpretationName]=defaultText\n",
        "  return interpretations\n",
        "\n",
        "# read from file\n",
        "interpretationTexts=initInterpretationTexts()\n",
        "\n",
        "# create one text area to enter interpretation comments\n",
        "def createTextArea(interpretationName):\n",
        "  wdgtNote=widgets.HTML(\n",
        "    value=\"<b><i>Interpretation note:</i></b>\"\n",
        "    )\n",
        "  wdgt=widgets.Textarea(\n",
        "    value=interpretationTexts[interpretationName],\n",
        "    placeholder=wdgtPlaceHolder + interpretationName,\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='800px', height='80px'))\n",
        "  interpretationWdgts[interpretationName]=wdgt\n",
        "  wdgtAll=widgets.VBox((wdgtNote,wdgt))\n",
        "  display(wdgtAll)\n",
        "\n",
        "# display the button to save the entered interpretation texts in the file.\n",
        "def createSaveButton():\n",
        "  button = widgets.Button(description='Save your inputs',background_color='gray',layout=widgets.Layout(width='200px'))\n",
        "  display(button)\n",
        "  button.on_click(on_click)\n",
        "# called back activated when the button is clicked\n",
        "# save the interpretations in a file.\n",
        "def on_click(b):\n",
        "  for i in range(len(interpretationList)):\n",
        "    interpretationTexts[interpretationList[i]]=interpretationWdgts[interpretationList[i]].value\n",
        "  with open(interpretationFile,'w') as outfile:\n",
        "    json.dump(interpretationTexts, outfile)\n",
        "  display(interpretationTexts)  \n",
        "#@title Default title text\n",
        "#lpMd=getLandProduct()\n",
        "#ipUrl=initImageProductsUrl()\n",
        "#platforms=initPlatforms(lpMd)\n",
        "#@title Generate Report Title\n",
        "def generateReportTitle(lpMd):\n",
        "  title=lpMd['properties']['title']\n",
        "  productFocus=lpMd['properties']['additionalAttributes']['product_focus']\n",
        "  display(widgets.HTML(\n",
        "  value=  \n",
        "  '<br><font size=\"18\"><center>Mapping Production</center></font>' +\n",
        "  '<br><font size=\"20\"><center>QUALITY ASSESSMENT REPORT</center></font>' +\n",
        "  '<br><font size=\"16\"><center>Demo: '+ title+'</center><font>'\n",
        "  ))\n",
        "\n",
        "generateReportTitle(lpMd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orw-S3cR8OQu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Prepared by:**\n",
        "\n",
        "QCMMS Team\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1. Introduction\n",
        "\n",
        "\n",
        "\n",
        "This document is the QCMMS Quality Assessment Report based\n",
        "on collected quality-related metadata by QC-Manager, stored in Catalog\n",
        "and analysed by QA-Report manager. The report\n",
        "\n",
        "-   provides insights about the quality of the whole mapping process (based on simplified analytic information);\n",
        "\n",
        "-   informs the service user, and the service provider, about the potential quality issues at each stage during the manufacturing of the land product;\n",
        "\n",
        "-   guides the reader to trace the error / uncertainty source from the report and catalogued metadata towards the critical process;\n",
        "\n",
        "-   and provides final quality assement about the mapped product (delivery: Yes / No).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-jYCu92fHzJ",
        "colab_type": "text"
      },
      "source": [
        "# 2. Applicable and Reference Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANi_TQ06fZ_K",
        "colab_type": "text"
      },
      "source": [
        "# 3. Terms, Definitions And Abbreviated Terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKnPZjK1foeD",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTr1DOzltiof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generateDefinitions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIks-zjtf6Nm",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Abbreviated Terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6Q4BTOttpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generateAbbreviations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_g1BuzTvcfo",
        "colab_type": "text"
      },
      "source": [
        "# 4. Processing Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pzQ4UtWeYF_",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Land Product Definitions\n",
        "\n",
        "This section provides a short overview of the land product\n",
        "definitions and specifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YNdKRL-4ruF",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "generate_lp_definition_report()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRZssje-62pn",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Production Feasibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8RGrtH47c05",
        "colab_type": "text"
      },
      "source": [
        "This section provides summary information about production feasibility based only on image archive metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDOtpO_p7CgE",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "if alreadyExecuted(IndexFeasibility):\n",
        "  for i in range(len(platforms)): \n",
        "     tableNbr=generateTableLabel(tableNbr,'General IP quality metadata overview as retrieved from archive for ' + platforms[i])\n",
        "     generate_feasibility_control_report(platforms[i])\n",
        "#createTextArea('feasibility')\n",
        "#@title \n",
        "  for i in range(len(platforms)): \n",
        "     fgNbr=generateHist(fgNbr,platforms[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzidfrzt7zGU",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Delivery Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F22p1jBD9EVG",
        "colab_type": "text"
      },
      "source": [
        "This assessment presents summary information about the delivery\n",
        "completeness\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESC2lrEr61Ce",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "if alreadyExecuted(IndexDelivery):\n",
        "  for i in range(len(platforms)): \n",
        "    tableNbr=generateTableLabel(tableNbr,'Tabulated overview of the delivery control for ' + platforms[i])\n",
        "    generate_delivery_control_report(platforms[i])\n",
        "#createTextArea('delivery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evBoSpY-890-",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Ordinary Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehsE4wOq9DdC",
        "colab_type": "text"
      },
      "source": [
        "This section provides summary information from the delivery\n",
        "completeness assessment. When available, \"LH\" in the following table is the \"Harmonized\" product level. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnwhFJpS7Cko",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "if alreadyExecuted(IndexOrdinary):\n",
        "  for i in range(len(platforms)):\n",
        "    tableNbr=generateTableLabel(tableNbr,'Tabulated overview of the L1 & L2 products ordinary control for '+ platforms[i])\n",
        "    generate_ordinary_control_report(platforms[i])\n",
        "#createTextArea('ordinary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9pt-5Dm-VYK",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 Detailed Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu51gBCVPvSA",
        "colab_type": "text"
      },
      "source": [
        "This control is focused on detailed pixel-level quality metadata. It provides summary information about the usability of individual pixels within each scene that passed the previous quality assessment procedure. In the end, each IP shall have associated valid pixel mask that represents pixels of good quality according to the requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moEGW2inEZ11",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "if alreadyExecuted(IndexDetailed):\n",
        "  for i in range(len(platforms)): \n",
        "    tableNbr=generateTableLabel(tableNbr,'Availability of the detailed pixel level quality metadata for '+ platforms[i])\n",
        "    generate_detailed_control_report(platforms[i])\n",
        "\n",
        "  for i in range(len(platforms)): \n",
        "    tableNbr=generateTableLabel(tableNbr,'Summary statistics of the pixel level quality metadata for '+ platforms[i])\n",
        "    generate_detailed_control_stat_report(platforms[i])\n",
        "\n",
        "  for i in range(len(platforms)):\n",
        "    #tableNbr=generateTableLabel(tableNbr,'Tabulated overview of the L1 & L2 products ordinary control for '+ platforms[i])\n",
        "    #print(platforms[i])\n",
        "    fgNbr=generate_Plot_CE(fgNbr,platforms[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cswIwG7o8imN",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 Fit-for-Purpose\n",
        "\n",
        "The following images present aggregations from valid pixel metadata over N image products computed by year (red= gaps)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RAlku2JuDL5",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "if alreadyExecuted(IndexIpForLp):\n",
        "  fgNbr=getFitForPurpose(fgNbr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSbpzWtX8qTq",
        "colab_type": "text"
      },
      "source": [
        "## 4.7 Production Quality Indicators\n",
        "\n",
        "Subject: Evaluate model indicators for traceability.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTpsNXp89oSW",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "if alreadyExecuted(IndexLpInterpretation):\n",
        "  tableNbr=generateTableLabel(tableNbr,'Interpretation model training indicators for Urban mask')\n",
        "  generate_production_and_validation_quality_indicators_report(\"http://qcmms.esa.int/quality-indicators/#lpInterpretationMetric\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVtt1Kh53Yld",
        "colab_type": "text"
      },
      "source": [
        "## 4.8 Validation Quality Indicators\n",
        "\n",
        "This section provides accuracy indicators of the independent validation for\n",
        "the resulting land product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8lwpsmO4UM7",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "if alreadyExecuted(IndexLpThematic):\n",
        "  tableNbr=generateTableLabel(tableNbr,'Land product independent validation indicators for Urban mask')\n",
        "  generate_production_and_validation_quality_indicators_report(\"http://qcmms.esa.int/quality-indicators/#lpThematicValidationMetric\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6HeWXYV_bVo",
        "colab_type": "text"
      },
      "source": [
        "## 4.9 Overall Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrIX9MZy_uR-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "This section provides an overall assessment of the quality analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUrCD1u6-osj",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "tableNbr=generateTableLabel(tableNbr,'Metric values for Image Products')\n",
        "displayIPsStatusBarchart()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCNgvyvNIVrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tableNbr=generateTableLabel(tableNbr,'Overall Assessment')\n",
        "generate_overall_assessment()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}